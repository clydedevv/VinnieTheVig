# File: api/insights.py

import logging
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional
from uuid import UUID

# LangGraph imports
from langchain_core.runnables import RunnableConfig
from langsearch.assistant.graph import graph   # The compiled StateGraph in graph.py
from langsearch.assistant.state import InsightsStateInput

# Services
from services.market_research_service import MarketResearchService

logger = logging.getLogger(__name__)
router = APIRouter()

# Pydantic request model for the endpoint
class InsightsRequest(BaseModel):
    insights_topic: str
    market_id: Optional[str] = None   # If you need to tie the analysis to a known market_id
    # any other custom fields you want

# Pydantic response model for clarity
class InsightsResponse(BaseModel):
    research_id: UUID
    analysis_id: UUID
    conclusion_id: UUID
    final_analysis: str

@router.post("/insights", response_model=InsightsResponse)
async def create_insight(request: InsightsRequest):
    """
    Endpoint that:
     1) Calls the LangGraph pipeline to run an analysis on 'insights_topic'.
     2) Stores the final output in the database.
     3) Returns the relevant DB IDs and final analysis text.
    """

    try:
        # 1) Prepare the state input
        state_input = InsightsStateInput(
            insights_topic=request.insights_topic
        )

        # 2) Optionally configure the pipeline:
        #    This can override defaults from environment or pass in specific config
        config = RunnableConfig(
            # 'configurable' is a dict that merges with environment variables inside Configuration
            configurable={
                "max_web_research_loops": 1,
                "openai_model": "gpt-4o-mini",
                "search_api": "perplexity"  # or "tavily"
            }
        )

        # 3) Execute the graph (the entire pipeline)
        output = graph.run(state_input, config=config)
        # output is an InsightsStateOutput with a field 'running_analysis'
        final_analysis = output.running_analysis

        if not final_analysis:
            raise ValueError("No analysis was generated by the pipeline.")

        # 4) Store the final analysis in your database
        #    We'll use MarketResearchService as an example. Adjust to your naming if needed.
        market_research_service = MarketResearchService()

        # Some random placeholders
        # - In a real usage, you might parse out a "conclusion_text" or "analysis_insights"
        #   from final_analysis. For now, we just store everything inside analysis_insights.
        analysis_insights = {"analysis": final_analysis}
        conclusion_text = "Generated by the LangGraph pipeline"
        confidence_score = 0.65  # Arbitrary placeholder

        # If the user didn't pass a real market_id, handle or generate one:
        market_id = request.market_id or "NO_MARKET"

        store_result = await market_research_service.store_market_research(
            market_id=market_id,
            title=f"Insights for {request.insights_topic}",
            raw_text=final_analysis,   # or a subset, if you'd rather store raw_text differently
            analysis_insights=analysis_insights,
            conclusion_text=conclusion_text,
            confidence_score=confidence_score,
            analyst="AI_Bot",
            analysis_type="NLP Summary"
        )

        # store_result is a dict with { "research_id", "analysis_id", "conclusion_id" }
        return InsightsResponse(
            research_id=store_result["research_id"],
            analysis_id=store_result["analysis_id"],
            conclusion_id=store_result["conclusion_id"],
            final_analysis=final_analysis
        )

    except Exception as e:
        logger.error(f"Error creating insights: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
